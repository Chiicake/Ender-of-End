# Ender of End 训练框架技术文档

> 范围：本文件描述**训练相关的总体框架**（含数据→标注→训练→评估→产物），以及与运行时的接口边界。
>
> 既定前提：
> - 主仓库 **Python-first**
> - 训练与训练相关套件全部在 **Linux（GPU 为主）**
> - 最终目标可在 **Windows** 运行；开发机需支持 **CPU 验证**
> - 底座模型：**Qwen3-VL-2B-Instruct**
> - 方案：外置 Long/Mid Goals + Planner/Controller 双 LoRA + MCP（Timeline+Retrieval）+ EventGate 分级
> - 四层任务框架：long goal（如完成日常），mid goal（如收菜），mid steps（如在基建收集物资、刷图1-7等）
---

## 1) 总体架构与数据流

```
+----------------------------+
| Collector                  |
|  - Capture (2FPS)          |
|  - RawInput aggregation    |
|  - action strings (500ms)  |
+--------------+-------------+
               |
               |  episode: frames + actions
               v
+--------------+-------------+        +----------------------------+
| Dataset Builder            |        | External Task Graph        |
|  (Python)                  | <------+  - Long Goal               |
|  - clean/slice/align       |        |  - Mid Goals               |
|  - span construction       |        |  - Mid Steps + evidence    |
|  - retrieval fields build  |        +----------------------------+
|  - emits train datasets    |
+-------+----------+---------+
        |          |
        |          |
        |          +-----------------------+
        |                                  |
        v                                  v
+-------+----------+              +--------+---------+
| VLM Labeler      |              | Action Toolkit   |
| (Python, Linux)  |              | (Python)         |
|  - recent/summary clip -> JSON  |              | parse/validate   |
|  - outputs DSL   |              | canonicalize     |
+-------+----------+              +--------+---------+
        |
        | labeled short_goal JSON
        v
+------------------------------+     +------------------------------+
| Planner Training             |     | Controller Training          |
| (Linux GPU)                  |     | (Linux GPU)                  |
|  - Qwen3-VL + Planner LoRA   |     |  - Qwen3-VL + Controller LoRA|
|  - input: recent/summary clip + retrieval   |     |  - input: image/history+DSL  |
|  - output: JSON (DSL plan)   |     |  - output: action string     |
+---------------+--------------+     +---------------+--------------+
                |                                |
                | artifacts: adapter weights     | artifacts: adapter weights
                v                                v
        +-------+--------------------------------+-------+
        |                Model Artifacts Pack            |
        |  - base model ref/version                      |
        |  - planner_lora / controller_lora              |
        |  - prompts/templates + JSON schema             |
        |  - eval reports + dataset versions             |
        +----------------------+-------------------------+
                               |
                               v
                      +--------+---------+
                      | Evaluation Suite |
                      | - offline metrics|
                      | - regression set |
                      +------------------+

```

---

## 1.5) 主仓库建议目录结构（参考经典 Python 项目）

> 目标：清晰分层、可复现、易测试、易发布。训练相关与运行时相关代码明确隔离；训练阶段依赖 Dataset Builder 的数据集解耦 Planner/Controller。

```
repo-root/
  README.md                        # 项目总览：快速开始、数据格式、训练/评估一键命令
  LICENSE                          # 开源协议
  pyproject.toml                   # Python 依赖与打包入口（推荐使用 Poetry/uv/pip-tools 任一）
  requirements/                    # （可选）按场景拆分依赖
    train.txt                      # 训练依赖（Linux/GPU）
    infer.txt                      # 推理依赖（Windows/WSL2）
    dev.txt                        # 开发依赖（lint/test）
  .gitignore
  .pre-commit-config.yaml          # （可选）格式化/静态检查钩子
  .github/
    workflows/
      ci.yml                       # CI：lint + unit tests + data smoke test

  configs/                         # 训练/标注/评估配置（YAML/JSON）
    dataset_builder.yaml
    labeler.yaml
    planner_train.yaml
    controller_train.yaml
    eval.yaml

  src/
    game_agent_train/
      __init__.py

      schemas/                     # JSON schema / Pydantic models（动作与计划契约）
        plan_schema.py
        action_schema.py

      action_toolkit/              # Action Toolkit：parse/validate/canonicalize
        parser.py
        validator.py
        canonicalizer.py

      dataset_builder/             # Dataset Builder：清洗、切片、span、retrieval 字段构造
        build_planner_dataset.py
        build_controller_dataset.py
        span.py
        retrieval_fields.py
        io.py

      labeler/                     # VLM Labeler：recent/summary clip -> plan_json（离线监督信号）
        run_labeler.py
        prompts.py
        postprocess.py

      training/
        planner/                   # Planner 训练入口与训练循环（LoRA）
          train.py
          data.py
          metrics.py
        controller/                # Controller 训练入口与训练循环（LoRA）
          train.py
          data.py
          metrics.py

      eval/                        # 离线评估与回归
        offline_eval.py
        regression.py

      packaging/                   # 模型产物打包：bundle 生成、版本写入
        pack_artifacts.py

      runtime_interfaces/          # 与运行时对接的协议层（HTTP payload、序列化）
        planner_api.py
        controller_api.py

  scripts/                         # 一键命令脚本（可选）
    build_datasets.sh
    run_labeler.sh
    train_planner.sh
    train_controller.sh
    eval_all.sh

  tests/                           # 单元测试与小型集成测试
    test_action_toolkit.py
    test_schemas.py
    test_span.py
    test_dataset_builder_smoke.py

  docs/                            # 工程文档与设计说明（可选）
    training_overview.md
    dataset_format.md
    evaluation.md

  assets/                          # （可选）小样例、示意图、schema 示例
    examples/
      sample_plan.json

  data/                            # （可选，不提交大文件）本地数据目录占位
    .gitkeep

  outputs/                         # （可选，不提交）训练输出：logs/checkpoints/reports
    .gitkeep
```

---

## 2) 组件清单（技术栈 + 主要作用 + I/O）

### 2.1 Collector（另仓库 https://github.com/Chiicake/End-VLM-data-collector）
- **技术栈**：Rust
- **主要作用**：
- 录制目标窗口游戏画面（2FPS）
- 聚合原始输入事件到 500ms step
- 输出动作字符串（含 15×33ms chunk）
- **输入**：游戏窗口
- **输出**：
  - `video/frames`（或视频文件）
- `actions.txt`（每 500ms 的 action string）

### 2.2 Dataset Builder（训练数据构建器）
- **技术栈**：Python（Linux/Windows 都可跑；训练侧通常 Linux）
- **主要作用**：
  - 清洗与对齐：帧/动作对齐、过滤异常段
  - **构造训练样本**：
    - Planner 数据集（含 retrieval 字段）
    - Controller 数据集（plan span 对齐）
  - 统一输出版本化数据集，确保可复现
- **输入**：由于mid_step是由VLM生成，所以可以不用输入
  - episode frames/video + actions
  - External Task Graph（Long/Mid Goals & Mid Steps）
  - （可选）来自 EventGate/MCP 的日志回流（用于 retrieval/失败样本）
- **输出**：
  - `planner_dataset`：`(recent_clip + summary_clip + mid_step + retrieved_memory) -> plan_json`
  - `controller_dataset`：`(image/history + plan_dsl) -> action_string`

### 2.3 VLM Labeler（标注器）
- **技术栈**：Python（Linux）；基于api，输入端口号连接到远端部署的模型进行数据传输和收集
- **主要作用**：
  - 将短视频片段（recent/summary clip）与当前 `mid_step` 转换为结构化 `plan_json`（含 DSL short_goal）
  - 产出训练监督信号（尤其用于 Planner 训练）
- **输入**：`recent_clip + summary_clip + mid_step_id/text (+ constraints)`
- **输出**：`plan_json`（short_goal_dsl / done_evidence / horizon / terminate_on / uncertainty）

### 2.4 Action Toolkit（动作协议工具）
- **技术栈**：Python
- **主要作用**：
  - 解析/校验/规范化 action string
  - 为训练与评估提供一致的动作语义
- **输入**：action string
- **输出**：结构化 action（dx/dy/dz + 6 chunks）与合法性判定

### 2.5 Planner Training（Planner-LoRA）
- **技术栈**：Linux + GPU；Python；Transformers + PEFT/LoRA（训练框架）
- **主要作用**：
  - 微调 Qwen3-VL，使其在给定 `recent_clip + summary_clip + mid_step + retrieved_memory` 时输出 `plan_json`
- **输入**：`planner_dataset`
- **输出**：`planner_lora` 权重 + 训练日志 + 评估报告

### 2.6 Controller Training（Controller-LoRA）
- **技术栈**：Linux + GPU；Python；Transformers + PEFT/LoRA（训练框架）
- **主要作用**：
  - 微调 Qwen3-VL，使其在给定 `image/history + plan_dsl` 时输出严格的 action string
- **输入**：`controller_dataset`
- **输出**：`controller_lora` 权重 + 训练日志 + 评估报告

> 说明：训练阶段 Planner 与 Controller **彼此独立训练**；没有端到端梯度传递，也不共享 batch。两者一致性主要由 Dataset Builder（数据构造规则、schema、版本）保证。

### 2.7 Model Artifacts Pack（模型产物打包）
- **技术栈**：Python（打包脚本）
- **主要作用**：
  - 将可部署的内容打包为一个版本化产物：
    - base model 引用/哈希
    - planner/controller LoRA
    - prompts/templates + JSON schema
    - 评估报告与数据集版本
- **输入**：训练产物与配置
- **输出**：可发布的 artifact bundle

### 2.8 Evaluation Suite（评估与回归）
- **技术栈**：Python（离线评估）；可选集成 Windows 在线回归
- **主要作用**：
  - 离线：格式率、动作误差、稳定性、span 质量、planner 检索利用等指标
  - 回归：固定小数据集/固定场景用例，保证每次更新不退化
- **输入**：模型产物 + 评估数据集
- **输出**：指标报告（JSON/HTML）

---

## 3) 训练阶段运行流程（按顺序）

### Step 0：准备输入数据
1. 使用 Collector 采集 episodes：`frames/video + actions`
2. 准备 External Task Graph：Long/Mid Goals 与 Mid Steps（含 step 文本与证据定义）

### Step 1：构建数据集（Dataset Builder）
1. 清洗与对齐：去掉异常段，保证 2FPS 与 500ms step 一致
2. 片段切分：为每个 mid_step 生成需要标注/训练的 recent_clip + summary_clip
3. 调用 VLM Labeler：recent/summary clip → plan_json（作为监督信号）
4. 生成：
   - Planner 数据集：把 `retrieved_memory` 字段（recent + topK）显式写入输入
   - Controller 数据集：构造 plan span，将 plan_dsl 绑定到 span 内每个 (image_t, action_t)

### Step 2：独立训练两个 LoRA
- Planner Training：用 planner_dataset 训练 Planner-LoRA
- Controller Training：用 controller_dataset 训练 Controller-LoRA

### Step 3：离线评估与产物打包
- Evaluation Suite：跑离线指标与回归集
- Model Artifacts Pack：生成可部署 bundle（含 schema/prompts 与版本信息）

---

## 4) 模块之间的联系（设计要点）

1. **Dataset Builder 是训练阶段的“中枢”**：
   - Planner 与 Controller 的训练数据来自不同构造规则
   - 训练阶段二者互不依赖；一致性靠 schema 与 span/retrieval 构造策略保证

2. **VLM Labeler 的角色是“提供结构化监督”**：
   - 它产出的 plan_json 主要监督 Planner；也为 Controller 的 span 构造提供 plan_dsl 与终止策略提示

3. **Action Toolkit 是训练/推理/评估的共同语言**：
   - 统一动作格式的解析与合法性判定
   - 确保训练指标与运行时校验一致

4. **评估产物与版本化非常关键**：
   - 每次模型/数据更新必须能追溯：base 模型版本、LoRA 版本、数据集版本、schema 版本

---

## 5) 与运行时的接口边界（仅列出训练侧必须交付的内容）

训练框架需要交付给运行时（Windows/WSL2）的最小集合：
- `planner_lora`、`controller_lora`
- `plan_json schema`（Planner 输出契约）
- `controller action string contract`（动作输出契约）
- prompts/templates（Planner 与 Controller 分离）
- 评估报告（用于选择可部署版本）

---

## 6) 最小可执行落地（本阶段目标）

- 目标：先跑通 “Collector → Dataset Builder → Labeler → 训练两个 LoRA → 离线评估” 的闭环。
- 约束：训练阶段不引入运行时复杂依赖（MCP/EventGate 可先仅作为日志输入源或占位字段），保证训练系统可独立复现。
